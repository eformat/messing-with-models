{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3482b0d-deb6-49f5-a498-026648f59af8",
   "metadata": {},
   "source": [
    "// https://huggingface.co/ibm-granite/granite-20b-functioncalling\n",
    "\n",
    "From the paper - Introducing Function calling abilities into Granite model family\n",
    "\n",
    "https://arxiv.org/pdf/2407.00121v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a411833-d3a7-4a1b-bc22-9c5bc1e1e2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -O granite-20b-functioncalling.i1-Q4_K_S.gguf https://huggingface.co/mradermacher/granite-20b-functioncalling-i1-GGUF/resolve/main/granite-20b-functioncalling.i1-Q4_K_S.gguf?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea19254c-2b94-45ca-956f-c29a6969a4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install 'huggingface_hub[cli,torch]'\n",
    "!pip install transformers==4.34.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ccc24-b084-40a5-aa36-4828aa42c9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login, logout\n",
    "import os\n",
    "login(os.getenv(\"HF_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e6e27-d380-4fab-b194-507539316c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download mradermacher/granite-20b-functioncalling-i1-GGUF granite-20b-functioncalling.i1-Q4_K_S.gguf --local-dir . --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c12ca-b3c1-4e2f-8c02-a0913edc46b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da98ee3-7f5f-4ed2-bd11-9805d0ba36e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" # or \"cpu\"\n",
    "model_path = \"ibm-granite/granite-20b-functioncalling\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b322d-b54d-40de-9b9f-5f5adc7aaccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!NVCC_APPEND_FLAGS='-allow-unsupported-compiler' CUDACXX=/usr/local/cuda/bin/nvcc CMAKE_ARGS=\"-DGGML_CUDA=on -DCMAKE_CUDA_ARCHITECTURES=all-major\" FORCE_CMAKE=1 pip install llama-cpp-python[server] --no-cache-dir --force-reinstall --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d2e2634-a88d-40ec-aa4f-de9103976b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 32 key-value pairs and 628 tensors from granite-20b-functioncalling.i1-Q4_K_S.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = starcoder\n",
      "llama_model_loader: - kv   1:                               general.name str              = StarCoder\n",
      "llama_model_loader: - kv   2:                   starcoder.context_length u32              = 8192\n",
      "llama_model_loader: - kv   3:                 starcoder.embedding_length u32              = 6144\n",
      "llama_model_loader: - kv   4:              starcoder.feed_forward_length u32              = 24576\n",
      "llama_model_loader: - kv   5:                      starcoder.block_count u32              = 52\n",
      "llama_model_loader: - kv   6:             starcoder.attention.head_count u32              = 48\n",
      "llama_model_loader: - kv   7:          starcoder.attention.head_count_kv u32              = 1\n",
      "llama_model_loader: - kv   8:     starcoder.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                          general.file_type u32              = 14\n",
      "llama_model_loader: - kv  10:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  11:                         tokenizer.ggml.pre str              = refact\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,49152]   = [\"<|endoftext|>\", \"<fim_prefix>\", \"<f...\n",
      "llama_model_loader: - kv  13:                  tokenizer.ggml.token_type arr[i32,49152]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.merges arr[str,48891]   = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"ĠĠĠĠ ĠĠ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 0\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 0\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {% set function_str = messages.get('f...\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  21:                                general.url str              = https://huggingface.co/mradermacher/g...\n",
      "llama_model_loader: - kv  22:              mradermacher.quantize_version str              = 2\n",
      "llama_model_loader: - kv  23:                  mradermacher.quantized_by str              = mradermacher\n",
      "llama_model_loader: - kv  24:                  mradermacher.quantized_at str              = 2024-07-10T10:57:34+02:00\n",
      "llama_model_loader: - kv  25:                  mradermacher.quantized_on str              = db1\n",
      "llama_model_loader: - kv  26:                         general.source.url str              = https://huggingface.co/ibm-granite/gr...\n",
      "llama_model_loader: - kv  27:                  mradermacher.convert_type str              = hf\n",
      "llama_model_loader: - kv  28:                      quantize.imatrix.file str              = granite-20b-functioncalling-i1-GGUF/i...\n",
      "llama_model_loader: - kv  29:                   quantize.imatrix.dataset str              = imatrix-training-full-3\n",
      "llama_model_loader: - kv  30:             quantize.imatrix.entries_count i32              = 208\n",
      "llama_model_loader: - kv  31:              quantize.imatrix.chunks_count i32              = 373\n",
      "llama_model_loader: - type  f32:  419 tensors\n",
      "llama_model_loader: - type q4_K:  202 tensors\n",
      "llama_model_loader: - type q5_K:    6 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens cache size = 19\n",
      "llm_load_vocab: token to piece cache size = 0.2826 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = starcoder\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 49152\n",
      "llm_load_print_meta: n_merges         = 48891\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 6144\n",
      "llm_load_print_meta: n_layer          = 52\n",
      "llm_load_print_meta: n_head           = 48\n",
      "llm_load_print_meta: n_head_kv        = 1\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 48\n",
      "llm_load_print_meta: n_embd_k_gqa     = 128\n",
      "llm_load_print_meta: n_embd_v_gqa     = 128\n",
      "llm_load_print_meta: f_norm_eps       = 1.0e-05\n",
      "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 24576\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Small\n",
      "llm_load_print_meta: model params     = 20.07 B\n",
      "llm_load_print_meta: model size       = 10.86 GiB (4.65 BPW) \n",
      "llm_load_print_meta: general.name     = StarCoder\n",
      "llm_load_print_meta: BOS token        = 0 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 0 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<|endoftext|>'\n",
      "llm_load_print_meta: PAD token        = 0 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 145 'Ä'\n",
      "llm_load_print_meta: EOT token        = 0 '<|endoftext|>'\n",
      "llm_load_print_meta: max token length = 512\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA L4, compute capability 8.9, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.55 MiB\n",
      "llm_load_tensors: offloading 52 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 53/53 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   428.25 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size = 10931.63 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =    13.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   13.00 MiB, K (f16):    6.50 MiB, V (f16):    6.50 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.19 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   120.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    25.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1933\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'quantize.imatrix.dataset': 'imatrix-training-full-3', 'general.source.url': 'https://huggingface.co/ibm-granite/granite-20b-functioncalling', 'mradermacher.quantized_on': 'db1', 'mradermacher.quantized_by': 'mradermacher', 'mradermacher.quantize_version': '2', 'tokenizer.chat_template': '{% set function_str = messages.get(\\'functions_str\\', {}) %}\\n{% set query = messages[\\'query\\'] %}\\n{% set sys_prompt = \\'You are a helpful assistant with access to the following function calls. Your task is to produce a sequence of function calls necessary to generate response to the user utterance. Use the following function calls as required. \\' %}\\n{% set funcstr = function_str|join(\\'\\n\\') %}\\n{{ \\'SYSTEM: \\' + sys_prompt + \\'\\n<|function_call_library|>\\n\\' + funcstr + \\'\\n\\nIf none of the functions are relevant or the given question lacks the parameters required by the function, please output \"<function_call> {\"name\": \"no_function\", \"arguments\": {}}\".\\n\\nUSER: \\' + query}}\\n{% if add_generation_prompt %}\\n{{ \\'ASSISTANT:\\' }}\\n{% endif %}\\n', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '0', 'quantize.imatrix.chunks_count': '373', 'quantize.imatrix.file': 'granite-20b-functioncalling-i1-GGUF/imatrix.dat', 'starcoder.context_length': '8192', 'mradermacher.convert_type': 'hf', 'general.url': 'https://huggingface.co/mradermacher/granite-20b-functioncalling-i1-GGUF', 'general.architecture': 'starcoder', 'starcoder.embedding_length': '6144', 'starcoder.feed_forward_length': '24576', 'quantize.imatrix.entries_count': '208', 'starcoder.block_count': '52', 'tokenizer.ggml.bos_token_id': '0', 'starcoder.attention.head_count': '48', 'starcoder.attention.head_count_kv': '1', 'starcoder.attention.layer_norm_epsilon': '0.000010', 'general.file_type': '14', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'mradermacher.quantized_at': '2024-07-10T10:57:34+02:00', 'general.name': 'StarCoder', 'tokenizer.ggml.pre': 'refact'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% set function_str = messages.get('functions_str', {}) %}\n",
      "{% set query = messages['query'] %}\n",
      "{% set sys_prompt = 'You are a helpful assistant with access to the following function calls. Your task is to produce a sequence of function calls necessary to generate response to the user utterance. Use the following function calls as required. ' %}\n",
      "{% set funcstr = function_str|join('\n",
      "') %}\n",
      "{{ 'SYSTEM: ' + sys_prompt + '\n",
      "<|function_call_library|>\n",
      "' + funcstr + '\n",
      "\n",
      "If none of the functions are relevant or the given question lacks the parameters required by the function, please output \"<function_call> {\"name\": \"no_function\", \"arguments\": {}}\".\n",
      "\n",
      "USER: ' + query}}\n",
      "{% if add_generation_prompt %}\n",
      "{{ 'ASSISTANT:' }}\n",
      "{% endif %}\n",
      "\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "llm = Llama(model_path=\"granite-20b-functioncalling.i1-Q4_K_S.gguf\", n_gpu_layers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059dc21f-16c5-4e96-af5c-206791ab8e83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# define the user query and list of available functions\n",
    "query = \"What's the current weather in New York?\"\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"description\": \"Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"ticker\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The stock ticker symbol, e.g. AAPL for Apple Inc.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"ticker\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# serialize functions and define a payload to generate the input template\n",
    "payload = {\n",
    "    \"functions_str\": [json.dumps(x) for x in functions],\n",
    "    \"query\": query,\n",
    "}\n",
    "\n",
    "instruction = tokenizer.apply_chat_template(payload, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# tokenize the text\n",
    "# input_tokens = tokenizer(instruction, return_tensors=\"pt\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759dad66-2d30-4b6a-a150-b9c12525ed84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     440.15 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /    26 runs   (    0.03 ms per token, 29919.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     439.73 ms /   324 tokens (    1.36 ms per token,   736.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.37 ms /    25 runs   (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:       total time =    1759.73 ms /   349 tokens\n"
     ]
    }
   ],
   "source": [
    "outputs = llm(instruction, max_tokens=500, stop=[\"<function_call>:\", \"\\n\"], echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64665217-fbc3-49de-9c5c-97812c573db7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-598b1212-1e5a-46db-a2cd-5be25dc426a3',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1723694903,\n",
       " 'model': 'granite-20b-functioncalling.i1-Q4_K_S.gguf',\n",
       " 'choices': [{'text': 'SYSTEM: You are a helpful assistant with access to the following function calls. Your task is to produce a sequence of function calls necessary to generate response to the user utterance. Use the following function calls as required. \\n<|function_call_library|>\\n{\"name\": \"get_current_weather\", \"description\": \"Get the current weather\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}}, \"required\": [\"location\"]}}\\n{\"name\": \"get_stock_price\", \"description\": \"Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"ticker\": {\"type\": \"string\", \"description\": \"The stock ticker symbol, e.g. AAPL for Apple Inc.\"}}, \"required\": [\"ticker\"]}}\\n\\nIf none of the functions are relevant or the given question lacks the parameters required by the function, please output \"<function_call> {\"name\": \"no_function\", \"arguments\": {}}\".\\n\\nUSER: What\\'s the current weather in New York?\\n<function_call> {\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"New York\"}}',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 324, 'completion_tokens': 25, 'total_tokens': 349}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1bf7454-4416-4e7b-98e9-c7e07406ec8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# define the user query and list of available functions\n",
    "query = \"What's the current IBM Stock Price?\"\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"description\": \"Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"ticker\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The stock ticker symbol, e.g. AAPL for Apple Inc.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"ticker\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# serialize functions and define a payload to generate the input template\n",
    "payload = {\n",
    "    \"functions_str\": [json.dumps(x) for x in functions],\n",
    "    \"query\": query,\n",
    "}\n",
    "\n",
    "instruction = tokenizer.apply_chat_template(payload, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# tokenize the text\n",
    "# input_tokens = tokenizer(instruction, return_tensors=\"pt\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b66c85-1d74-40ce-a0e8-cf34b21327c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 318 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =     440.15 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /    26 runs   (    0.04 ms per token, 27282.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      64.08 ms /     5 tokens (   12.82 ms per token,    78.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1300.93 ms /    25 runs   (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:       total time =    1379.41 ms /    30 tokens\n"
     ]
    }
   ],
   "source": [
    "outputs = llm(instruction, max_tokens=500, stop=[\"<function_call>:\", \"\\n\"], echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c640f5-32f3-43fa-a314-4d817ec80b77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-ec69510b-0c28-4c6e-983c-28887937b23c',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1723695158,\n",
       " 'model': 'granite-20b-functioncalling.i1-Q4_K_S.gguf',\n",
       " 'choices': [{'text': 'SYSTEM: You are a helpful assistant with access to the following function calls. Your task is to produce a sequence of function calls necessary to generate response to the user utterance. Use the following function calls as required. \\n<|function_call_library|>\\n{\"name\": \"get_current_weather\", \"description\": \"Get the current weather\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}}, \"required\": [\"location\"]}}\\n{\"name\": \"get_stock_price\", \"description\": \"Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"ticker\": {\"type\": \"string\", \"description\": \"The stock ticker symbol, e.g. AAPL for Apple Inc.\"}}, \"required\": [\"ticker\"]}}\\n\\nIf none of the functions are relevant or the given question lacks the parameters required by the function, please output \"<function_call> {\"name\": \"no_function\", \"arguments\": {}}\".\\n\\nUSER: What\\'s the current IBM Stock Price?\\n<function_call> {\"name\": \"get_stock_price\", \"arguments\": {\"ticker\": \"IBM\"}} ',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 323, 'completion_tokens': 25, 'total_tokens': 348}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c601d57e-e241-4012-88a0-00a97a1fd0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# define the user query and list of available functions\n",
    "query = \"Should i buy NVIDIA stock when its raining in Sydney?\"\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"description\": \"Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"ticker\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The stock ticker symbol, e.g. AAPL for Apple Inc.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"ticker\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# serialize functions and define a payload to generate the input template\n",
    "payload = {\n",
    "    \"functions_str\": [json.dumps(x) for x in functions],\n",
    "    \"query\": query,\n",
    "}\n",
    "\n",
    "instruction = tokenizer.apply_chat_template(payload, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# tokenize the text\n",
    "# input_tokens = tokenizer(instruction, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fe2a2bf-d80a-46ba-96c9-c23e8f2f52c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 320 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =     440.15 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    53 runs   (    0.04 ms per token, 24801.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =      66.34 ms /     9 tokens (    7.37 ms per token,   135.66 tokens per second)\n",
      "llama_print_timings:        eval time =    2718.90 ms /    52 runs   (   52.29 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:       total time =    2820.24 ms /    61 tokens\n"
     ]
    }
   ],
   "source": [
    "outputs = llm(instruction, max_tokens=500, stop=[\"<function_call>:\", \"\\n\"], echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b6efc80-9e16-4726-b1f7-e91d2dbd13f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-03b8f24a-558e-4358-bae3-b6095d2c17a9',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1723695364,\n",
       " 'model': 'granite-20b-functioncalling.i1-Q4_K_S.gguf',\n",
       " 'choices': [{'text': 'SYSTEM: You are a helpful assistant with access to the following function calls. Your task is to produce a sequence of function calls necessary to generate response to the user utterance. Use the following function calls as required. \\n<|function_call_library|>\\n{\"name\": \"get_current_weather\", \"description\": \"Get the current weather\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}}, \"required\": [\"location\"]}}\\n{\"name\": \"get_stock_price\", \"description\": \"Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"ticker\": {\"type\": \"string\", \"description\": \"The stock ticker symbol, e.g. AAPL for Apple Inc.\"}}, \"required\": [\"ticker\"]}}\\n\\nIf none of the functions are relevant or the given question lacks the parameters required by the function, please output \"<function_call> {\"name\": \"no_function\", \"arguments\": {}}\".\\n\\nUSER: Should i buy NVIDIA stock when its raining in Sydney?\\n<function_call> {\"name\": \"get_stock_price\", \"arguments\": {\"ticker\": \"NVIDIA\"}} <function_call> {\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"Sydney\"}} ',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 329, 'completion_tokens': 52, 'total_tokens': 381}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195eb309-f5e3-47b7-ad15-8864c8687dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
